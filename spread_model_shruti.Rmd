---
title: "Playoffs 2 Spread Model"
author: "Shruti Gopalswamy"
output: html_notebook
---

# Importing the Data
```{r}
games <-  read.csv("https://raw.githubusercontent.com/mattymo18/STOR-538-Project2-2021/master/Source-Data/games.csv")
game_details <- read.csv("https://raw.githubusercontent.com/mattymo18/STOR-538-Project2-2021/master/Source-Data/games_details.csv")
teams <- read.csv("https://raw.githubusercontent.com/mattymo18/STOR-538-Project2-2021/master/Source-Data/teams.csv")

all_game_data <- read.csv("https://raw.githubusercontent.com/john-lickteig/playoff2/master/all_game_data.csv")
game_details_cleaned <- read.csv("https://raw.githubusercontent.com/john-lickteig/playoff2/master/game_details_cleaned.csv")
games_cleaned <- read.csv("https://raw.githubusercontent.com/john-lickteig/playoff2/master/games_cleaned.csv")

final_game_data_with_rolling_avg <- read.csv("https://raw.githubusercontent.com/john-lickteig/playoff2/master/final_game_data_with_rolling_avg.csv")
```



## Variable Selection Using Stepwise Selection Method

Starting with a basic linear regression model with all the numeric variables as predictors (except PTS_home and PTS_away as those are used to calculate Spread directly) as the baseline, and using the stepwise selection method with Cp as the criteria to narrow predictors down to the most significant one(s) for predicting Spread, we came up with the linear regression model with equation 

Spread = 0.09071(OREB_away) + 1.64248 (with AIC=2.19) 


Thus, using stepwise selection we found that `OREB_away` alone to be the most significant predictor of `Spread`. 

```{r}
# Fit the full model as the baseline linear reg. model
Full=lm(Spread~Total+OREB_home+OREB_away+OREB, data=all_game_data)

# Find the MSE for the baseline full model
MSE=(summary(Full)$sigma)^2

# Start the stepwise selection process with a model with no predictors
none=lm(Spread~1,data=all_game_data)
step(none,scope=list(upper=Full),scale=MSE)
```




## Variable Selection with New Rolling Avg Variable Using Stepwise Selection Method

Starting with a basic linear regression model with all the numeric team-level variables as predictors (except PTS_home and PTS_away as those are used to calculate Spread directly) as the baseline linear model, and using the stepwise selection method with Cp as the criteria to narrow predictors down to the most significant one(s) for predicting Spread, we came up with the linear regression model with equation below.

Spread = 3.151e-02(PM_home) + 1.030e-04(AST_away) + -1.099e-04(FGA_home) + -2.899e-01(FG3M_away) + 2.898e-01(Total) + -5.796e-01(FGM) + -2.898e-01(FG3M_home) + -2.897e-01(FTM) + -1.685e-01(PM_away) + -9.262e-05(FTA_away) + 8.811e-05 (FG3A_away) + -9.853e-05(TO_home) + 9.583e-05(AST_home) + 8.358e-03 

AIC decreased from 4562503013 (empty model) to 9527.17 (above lm)

Thus, using stepwise selection we found that the team-level variables `PM_home`, `AST_away`, `FGA_home`, `FG3M_away`, `Total`, `FGM`, `FG3M_home`, `FTM`, `PM_away`, `FTA_away`, `FG3A_away`, `TO_home`, `AST_home` to be the most significant predictors of `Spread`. 

```{r}
# Fit the full model as the baseline linear reg. model
Full=lm(Spread ~ . - X - GAME_DATE_EST - Home.Team - Away.Team - PTS_home - PTS_away, data=final_game_data_with_rolling_avg)

# Find the MSE for the baseline full model
MSE=(summary(Full)$sigma)^2

# Start the stepwise selection process with a model with no predictors
none=lm(Spread~1,data=final_game_data_with_rolling_avg)
step(none,scope=list(upper=Full),scale=MSE)
```


```{r}
shruti_spread_model_1 = lm(formula = Spread ~ PM_home + AST_away + FGA_home + FG3M_away + Total + FGM + FG3M_home + FTM + PM_away + FTA_away + FG3A_away + TO_home + AST_home, data = final_game_data_with_rolling_avg)

summary(shruti_spread_model_1)
```

## Checking for multicollinearity between the predictors included in shruti_spread_model_1


Since the focus of the spread model is on making inferences regarding the relative importance of the predictors, and would likely be used to make predictions in a different basketball data set, in which the correlations may be different, a high VIF may be problematic. A high VIF makes it hard to disentangle the relative importance of predictors to the response, spread, in a model, and leads to a more inflated std. error (and thus variance/R^2), thereby a smaller chance that the correlation coefficient of a predictor is statistically significant.

There are no VIF greater than 5 (or > 2,5, if taking a more conservative approach) for any of the predictors included in the spread model, indicating a lack of inflation due to multicollinearity within the linear model.

```{r}
round(cor(final_game_data_with_rolling_avg[5:50]),2)
```
```{r}
vif<- function(model, ...) {  
  V <- summary(model)$cov.unscaled
  Vi <- crossprod(model.matrix(model))
	nam <- names(coef(model))
  if(k <- match("(Intercept)", nam, nomatch = F)) {
		v1 <- diag(V)[-k]
		v2 <- (diag(Vi)[-k] - Vi[k, -k]^2/Vi[k,k])
		nam <- nam[-k]
	} else {
		v1 <- diag(V)
		v2 <- diag(Vi)
		warning("No intercept term detected.  Results may
surprise.")
	}
	structure(v1*v2, names = nam)
}

vif(shruti_spread_model_1)
```

# Next: cross validate model with training data

# Then: repeat stepwise process after cross validation

